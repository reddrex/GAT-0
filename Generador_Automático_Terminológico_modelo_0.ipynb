{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhmPWBW5IuMyynbUa/6doh"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYa-BagOOg0c",
        "outputId": "d3128fda-9ee3-4f47-d881-2985039e2a99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.3-py3-none-any.whl (327 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importamos la librería de openai para poder usar sus modelos del lenguaje\n",
        "import openai\n",
        "#importamos files de colab para poder cargar nuestros archivos de google colab\n",
        "from google.colab import files\n",
        "\n",
        "#introducimos nuestra clave de la api, para poder hacer uso de los servicios de Open AI\n",
        "openai.api_key = 'your-api-key'"
      ],
      "metadata": {
        "id": "z4gTO6DAN1dV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vamos a crear una función para cargar los contextos que ya habremos extraído manualmente de los documentos\n",
        "#también podríamos automatizar esta parte hasta cierto punto y coger todos los documentos, buscar con expresiones regulares los enunciados\n",
        "#en los que aparece el término y luego sacar una lista. Sin embargo, hemos preferido hacerlo de manera manual porque podemos darle\n",
        "#parte del contexto en el que no aparezca necesariamente el término pero sí encontremos información que enriquezca el contexto.\n",
        "\n",
        "def cargar_textos():\n",
        "  contextos=[]\n",
        "  continuar=True\n",
        "  while continuar:\n",
        "    print(\"A continuación, carga el archivo .txt que contiene uno de los contextos.\\n\")\n",
        "    nube=files.upload()\n",
        "    for clave in nube.keys():\n",
        "      print(f\"Archivo {clave} subido con éxito.\\n\")\n",
        "      tx=nube[clave].decode('utf-8')\n",
        "      contextos.append(tx)\n",
        "    respuesta=input(\"¿Quieres cargar otro archivo? (s/n): \").strip().lower() #como files solo nos deja cargar un archivo cada vez, repetimos lo mismo hasta que el usuario no quiera cargar más archivos\n",
        "    if respuesta != 's':\n",
        "      continuar = False\n",
        "  return contextos\n"
      ],
      "metadata": {
        "id": "xaioW7KVOTrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ahora vamos a crear la función para extraer la información de los contextos proporcionados, esta será la primera llamada que haremos al modelo\n",
        "\n",
        "def extractor_info(termino, contextos):\n",
        "  prompt=f\"Extrae la información más relevante de cada contexto sobre 'qué es {termino}' de los siguientes contextos, si no te ofrece información sobre qué es o sus características, no prestes atención al contexto:\"\n",
        "  for i, contexto in enumerate(contextos, 1):\n",
        "    prompt+=f\"[contexto {i}] '{contexto}' [fin contexto {i}], \"\n",
        "  respuesta = openai.Completion.create(engine=\"text-davinci-003\", prompt=prompt, max_tokens=200, temperature=0.5)\n",
        "  info=str(respuesta.choices[0].text.strip())\n",
        "  return info\n"
      ],
      "metadata": {
        "id": "OfzhVfoLUl0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vamos a crear una función para la generación de las definiciones a partir de la información\n",
        "\n",
        "def generacion_definicion(termino, resumen):\n",
        "  prompt=f\"Utilizando solo la información necesaria de la que te voy a proporcionar, debes elaborar una definición propia del término '{termino}', siguiendo la siguiente fórmula: Término = hiperónimo + características distintivas. Por ejemplo, 'Las eyectivas son [hiperónimo] [características distintivas]'. La información comienza aquí: {resumen}\"\n",
        "  respuesta=openai.Completion.create(engine=\"text-davinci-003\", prompt=prompt, max_tokens=120, temperature=0.5)\n",
        "  definicion=str(respuesta.choices[0].text.strip())\n",
        "  return definicion\n"
      ],
      "metadata": {
        "id": "5fVATkJXWbbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  termino=input(\"Introduce el término a definir: \")\n",
        "  contextos=cargar_textos()\n",
        "  print(\"\\n\")\n",
        "  print(\"Resumiendo contextos...\\n\")\n",
        "  resumen=extractor_info(termino, contextos)\n",
        "  print(\"Contextos resumidos con éxito.\\n\")\n",
        "  print(\"Generando la definición...\\n\")\n",
        "  definicion=generacion_definicion(termino, resumen)\n",
        "  print(\"Definición generada con éxito.\\n\")\n",
        "  print(f\"Definicion de {termino}: {definicion}\")\n"
      ],
      "metadata": {
        "id": "m-Er06NrXy2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__==\"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "id": "6vWK8X_saOF6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}